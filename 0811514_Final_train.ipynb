{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86d4502e",
   "metadata": {},
   "source": [
    "## Install dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1444b6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy==1.20.3 in /usr/local/anaconda3/lib/python3.9/site-packages (1.20.3)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas==1.3.4 in /usr/local/anaconda3/lib/python3.9/site-packages (1.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/anaconda3/lib/python3.9/site-packages (from pandas==1.3.4) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/anaconda3/lib/python3.9/site-packages (from pandas==1.3.4) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/anaconda3/lib/python3.9/site-packages (from pandas==1.3.4) (1.20.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas==1.3.4) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib==3.4.3 in /usr/local/anaconda3/lib/python3.9/site-packages (3.4.3)\n",
      "Requirement already satisfied: numpy>=1.16 in /usr/local/anaconda3/lib/python3.9/site-packages (from matplotlib==3.4.3) (1.20.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/anaconda3/lib/python3.9/site-packages (from matplotlib==3.4.3) (3.0.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/anaconda3/lib/python3.9/site-packages (from matplotlib==3.4.3) (8.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/anaconda3/lib/python3.9/site-packages (from matplotlib==3.4.3) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/anaconda3/lib/python3.9/site-packages (from matplotlib==3.4.3) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/anaconda3/lib/python3.9/site-packages (from matplotlib==3.4.3) (1.3.1)\n",
      "Requirement already satisfied: six in /usr/local/anaconda3/lib/python3.9/site-packages (from cycler>=0.10->matplotlib==3.4.3) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: colorama==0.4.4 in /usr/local/anaconda3/lib/python3.9/site-packages (0.4.4)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn==1.2.0 in /home/shadowpa0327/.local/lib/python3.9/site-packages (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/anaconda3/lib/python3.9/site-packages (from scikit-learn==1.2.0) (1.20.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/anaconda3/lib/python3.9/site-packages (from scikit-learn==1.2.0) (1.7.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/shadowpa0327/.local/lib/python3.9/site-packages (from scikit-learn==1.2.0) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/anaconda3/lib/python3.9/site-packages (from scikit-learn==1.2.0) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.20.3\n",
    "!pip install pandas==1.3.4\n",
    "!pip install matplotlib==3.4.3\n",
    "!pip install colorama==0.4.4\n",
    "!pip install scikit-learn==1.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "387dd7be",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-09-01T00:05:46.694503Z",
     "iopub.status.busy": "2022-09-01T00:05:46.693906Z",
     "iopub.status.idle": "2022-09-01T00:05:49.134311Z",
     "shell.execute_reply": "2022-09-01T00:05:49.133250Z"
    },
    "papermill": {
     "duration": 2.453915,
     "end_time": "2022-09-01T00:05:49.137496",
     "exception": false,
     "start_time": "2022-09-01T00:05:46.683581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from colorama import Fore, Back, Style\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LogisticRegression, HuberRegressor\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from scipy.stats import pearsonr, spearmanr, rankdata\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "91802174",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-01T00:05:49.153444Z",
     "iopub.status.busy": "2022-09-01T00:05:49.152821Z",
     "iopub.status.idle": "2022-09-01T00:05:49.469797Z",
     "shell.execute_reply": "2022-09-01T00:05:49.468027Z"
    },
    "papermill": {
     "duration": 0.328763,
     "end_time": "2022-09-01T00:05:49.473319",
     "exception": false,
     "start_time": "2022-09-01T00:05:49.144556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (26570, 26), test (20775, 25)\n",
      "failure 0: 20921, failure 1: 5649\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('./input/train.csv')\n",
    "test = pd.read_csv('./input/test.csv')\n",
    "submission = pd.read_csv('./input/sample_submission.csv')\n",
    "print(f'train {train.shape}, test {test.shape}')\n",
    "print(f'failure 0: {train[train.failure==0].shape[0]}, failure 1: {train[train.failure==1].shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c3a565a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-01T00:05:49.488884Z",
     "iopub.status.busy": "2022-09-01T00:05:49.488495Z",
     "iopub.status.idle": "2022-09-01T00:05:49.512890Z",
     "shell.execute_reply": "2022-09-01T00:05:49.511787Z"
    },
    "papermill": {
     "duration": 0.035195,
     "end_time": "2022-09-01T00:05:49.515731",
     "exception": false,
     "start_time": "2022-09-01T00:05:49.480536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.concat([train, test])\n",
    "data['m3_missing'] = data['measurement_3'].isnull().astype(np.int8)\n",
    "data['m5_missing'] = data['measurement_5'].isnull().astype(np.int8)\n",
    "data['loading'] = np.log1p(data['loading'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74314b96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-01T00:05:49.531567Z",
     "iopub.status.busy": "2022-09-01T00:05:49.530784Z",
     "iopub.status.idle": "2022-09-01T00:06:02.266889Z",
     "shell.execute_reply": "2022-09-01T00:06:02.265631Z"
    },
    "papermill": {
     "duration": 12.747436,
     "end_time": "2022-09-01T00:06:02.270046",
     "exception": false,
     "start_time": "2022-09-01T00:05:49.522610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code A has 386 samples to fill nan\n",
      "KNN imputing code A\n",
      "code B has 418 samples to fill nan\n",
      "KNN imputing code B\n",
      "code C has 391 samples to fill nan\n",
      "KNN imputing code C\n",
      "code D has 398 samples to fill nan\n",
      "KNN imputing code D\n"
     ]
    }
   ],
   "source": [
    "feature = [f for f in test.columns if f.startswith('measurement') or f=='loading']\n",
    "fill_dict = {\n",
    "    'A': ['measurement_5','measurement_6','measurement_8'],\n",
    "    'B': ['measurement_4','measurement_5','measurement_7'],\n",
    "    'C': ['measurement_5','measurement_7','measurement_8','measurement_9'],\n",
    "    'D': ['measurement_5','measurement_6','measurement_7','measurement_8'],\n",
    "    'E': ['measurement_4','measurement_5','measurement_6','measurement_8'],\n",
    "    'F': ['measurement_4','measurement_5','measurement_6','measurement_7'],\n",
    "    'G': ['measurement_4','measurement_6','measurement_8','measurement_9'],\n",
    "    'H': ['measurement_4','measurement_5','measurement_7','measurement_8','measurement_9'],\n",
    "    'I': ['measurement_3','measurement_7','measurement_8']\n",
    "}\n",
    "\n",
    "for code in data.product_code.unique():\n",
    "    tmp = data[data.product_code==code]\n",
    "    column = fill_dict[code]\n",
    "    tmp_train = tmp[column+['measurement_17']].dropna(how='any')\n",
    "    tmp_test = tmp[(tmp[column].isnull().sum(axis=1)==0)&(tmp['measurement_17'].isnull())]\n",
    "    print(f\"code {code} has {len(tmp_test)} samples to fill nan\")\n",
    "    model = HuberRegressor()\n",
    "    model.fit(tmp_train[column], tmp_train['measurement_17'])\n",
    "    data.loc[(data.product_code==code)&(data[column].isnull().sum(axis=1)==0)&(data['measurement_17'].isnull()), 'measurement_17'] = model.predict(tmp_test[column])\n",
    "\n",
    "    model2 = KNNImputer(n_neighbors=5)\n",
    "    print(f\"KNN imputing code {code}\")\n",
    "    data.loc[data.product_code==code, feature] = model2.fit_transform(data.loc[data.product_code==code, feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9065f6dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-01T00:06:02.288546Z",
     "iopub.status.busy": "2022-09-01T00:06:02.287825Z",
     "iopub.status.idle": "2022-09-01T00:06:02.296196Z",
     "shell.execute_reply": "2022-09-01T00:06:02.295159Z"
    },
    "papermill": {
     "duration": 0.020582,
     "end_time": "2022-09-01T00:06:02.298803",
     "exception": false,
     "start_time": "2022-09-01T00:06:02.278221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _scale(train_data, val_data, test_data, feats):\n",
    "    scaler = StandardScaler()\n",
    "    # scaler = PowerTransformer()\n",
    "    \n",
    "    scaled_train = scaler.fit_transform(train_data[feats])\n",
    "    scaled_val = scaler.transform(val_data[feats])\n",
    "    scaled_test = scaler.transform(test_data[feats])\n",
    "    \n",
    "    #back to dataframe\n",
    "    new_train = train_data.copy()\n",
    "    new_val = val_data.copy()\n",
    "    new_test = test_data.copy()\n",
    "    \n",
    "    new_train[feats] = scaled_train\n",
    "    new_val[feats] = scaled_val\n",
    "    new_test[feats] = scaled_test\n",
    "    \n",
    "    assert len(train_data) == len(new_train)\n",
    "    assert len(val_data) == len(new_val)\n",
    "    assert len(test_data) == len(new_test)\n",
    "    \n",
    "    return new_train, new_val, new_test\n",
    "\n",
    "def get_scaler(train_data, feats):\n",
    "    scaler = StandardScaler()\n",
    "    # scaler = PowerTransformer()\n",
    "    \n",
    "    scaled_train = scaler.fit(train_data[feats])\n",
    "\n",
    "    \n",
    "    #back to dataframe\n",
    "    new_train = train_data.copy()\n",
    "\n",
    "    \n",
    "    new_train[feats] = scaled_train\n",
    "\n",
    "    \n",
    "    assert len(train_data) == len(new_train)\n",
    "\n",
    "    return scaler\n",
    "\n",
    "def apply_transform(data, scaler, feats):\n",
    "    \n",
    "    #back to dataframe\n",
    "    scaled_data = scaler.transform(data[feats])\n",
    "    new_data = data.copy()\n",
    "    \n",
    "    \n",
    "    new_data [feats] = scaled_data\n",
    "\n",
    "    \n",
    "    assert len(new_data) == len(data)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e669b62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-01T00:06:02.316319Z",
     "iopub.status.busy": "2022-09-01T00:06:02.315460Z",
     "iopub.status.idle": "2022-09-01T00:06:02.334175Z",
     "shell.execute_reply": "2022-09-01T00:06:02.332750Z"
    },
    "papermill": {
     "duration": 0.031629,
     "end_time": "2022-09-01T00:06:02.337950",
     "exception": false,
     "start_time": "2022-09-01T00:06:02.306321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = data[data.failure.notnull()]\n",
    "test = data[data.failure.isnull()]\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97328034",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-01T00:06:02.355693Z",
     "iopub.status.busy": "2022-09-01T00:06:02.355277Z",
     "iopub.status.idle": "2022-09-01T00:06:02.370452Z",
     "shell.execute_reply": "2022-09-01T00:06:02.369227Z"
    },
    "papermill": {
     "duration": 0.026817,
     "end_time": "2022-09-01T00:06:02.373141",
     "exception": false,
     "start_time": "2022-09-01T00:06:02.346324",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = train.drop(['failure'], axis=1)\n",
    "y = train['failure'].astype(int)\n",
    "test = test.drop(['failure'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364c60a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TPSSolver:\n",
    "    def __init__(self):\n",
    "        self.models = []\n",
    "        self.model_feature_importance_lists = []\n",
    "        self.standScalers = []\n",
    "    def train(self, X, y, k_fold_split_nums = 5, select_feature = None):\n",
    "        lr_oof_1 = np.zeros(len(train))\n",
    "        lr_oof_2 = np.zeros(len(train))\n",
    "        lr_auc = 0\n",
    "        lr_acc = 0\n",
    "        kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "        feature_importance_lists = []\n",
    "        for fold_idx, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "            print(\"Fold:\", fold_idx+1)\n",
    "            x_train, x_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            #x_test = test.copy()\n",
    "\n",
    "            #x_train, x_val = _scale(x_train, x_val, select_feature)\n",
    "            scaler = get_scaler(x_train, select_feature)\n",
    "            self.standScalers.append(scaler)\n",
    "            x_train = apply_transform(x_train,scaler,  select_feature)\n",
    "            x_val =  apply_transform( x_val, scaler, select_feature)\n",
    "            model = LogisticRegression(max_iter=1000, C=0.0001, penalty='l2', solver='newton-cg') # , class_weight='balanced'\n",
    "            model.fit(x_train[select_feature], y_train)\n",
    "            self.models.append((model, select_feature))\n",
    "            feature_importance_lists.append(model.coef_.ravel())\n",
    "\n",
    "            val_preds = model.predict_proba(x_val[select_feature])[:, 1]\n",
    "            lr_auc += roc_auc_score(y_val, val_preds) / 5\n",
    "            y_preds = model.predict(x_val[select_feature])\n",
    "            lr_acc += accuracy_score(y_val, y_preds) / 5\n",
    "            lr_oof_1[val_idx] = val_preds\n",
    "            lr_oof_2[val_idx] = y_preds\n",
    "        self.model_feature_importance_lists.append(feature_importance_lists)\n",
    "        print(f\"{Fore.GREEN}{Style.BRIGHT}Average auc = {round(lr_auc, 5)}, Average acc = {round(lr_acc, 5)}{Style.RESET_ALL}\")\n",
    "        print(f\"{Fore.RED}{Style.BRIGHT}OOF auc = {round(roc_auc_score(y, lr_oof_1), 5)}, OOF acc = {round(accuracy_score(y, lr_oof_2), 5)}{Style.RESET_ALL}\")\n",
    "    \n",
    "    def visualization_importance_scores(self, i):\n",
    "        importance_list =  self.model_feature_importance_lists[i]\n",
    "        _, select_feature = self.models[i]\n",
    "        importance_df = pd.DataFrame(np.array(importance_list).T, index=select_feature)\n",
    "        importance_df['mean'] = importance_df.mean(axis=1).abs()\n",
    "        importance_df['feature'] = select_feature\n",
    "        importance_df = importance_df.sort_values('mean', ascending=False).reset_index().head(20)\n",
    "        plt.barh(importance_df.index, importance_df['mean'], color='lightgreen')\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.yticks(ticks=importance_df.index, labels=importance_df['feature'])\n",
    "        plt.title('LogisticRegression feature importances')\n",
    "        plt.show()\n",
    "        \n",
    "    def inference(self, X):\n",
    "        lr_inference = np.zeros(len(X))\n",
    "        for scaler, (model, select_feature) in zip(self.standScalers,self.models):\n",
    "            x_inference = apply_transform(X, scaler, select_feature)\n",
    "            lr_inference += model.predict_proba(x_inference[select_feature])[:, 1] / len(self.models)\n",
    "        return lr_inference\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168c3018",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-01T00:06:02.390577Z",
     "iopub.status.busy": "2022-09-01T00:06:02.389701Z",
     "iopub.status.idle": "2022-09-01T00:06:02.395457Z",
     "shell.execute_reply": "2022-09-01T00:06:02.394496Z"
    },
    "papermill": {
     "duration": 0.017336,
     "end_time": "2022-09-01T00:06:02.398081",
     "exception": false,
     "start_time": "2022-09-01T00:06:02.380745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "select_features = [['m3_missing', 'm5_missing', 'measurement_1', 'measurement_4', 'loading', 'measurement_17', 'attribute_3'],\n",
    "                  ['measurement_1', 'measurement_4', 'loading', 'measurement_17', 'attribute_3'],\n",
    "                  ['m3_missing', 'm5_missing', 'measurement_4', 'loading', 'measurement_17'],\n",
    "                  ['measurement_4', 'loading', 'measurement_17'],\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf443202",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ensemble_models = []\n",
    "for i, select_feature in enumerate(select_features):\n",
    "    model = TPSSolver()\n",
    "    model.train(X, y, k_fold_split_nums = 5, select_feature = select_feature)\n",
    "    ensemble_models.append(model)\n",
    "    submission[f\"lr{i}\"] = model.inference(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10460079",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, model in enumerate(ensemble_models):\n",
    "    model.visualization_importance_scores(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1c7625",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9d621c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-01T00:06:06.590854Z",
     "iopub.status.busy": "2022-09-01T00:06:06.590379Z",
     "iopub.status.idle": "2022-09-01T00:06:06.637458Z",
     "shell.execute_reply": "2022-09-01T00:06:06.636245Z"
    },
    "papermill": {
     "duration": 0.061575,
     "end_time": "2022-09-01T00:06:06.640254",
     "exception": false,
     "start_time": "2022-09-01T00:06:06.578679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission['rank0'] = rankdata(submission['lr0'])\n",
    "submission['rank1'] = rankdata(submission['lr1'])\n",
    "submission['rank2'] = rankdata(submission['lr2'])\n",
    "submission['rank3'] = rankdata(submission['lr3'])\n",
    "submission['failure'] = submission['rank0']*0.2 + submission['rank1']*0.25 + submission['rank2']*0.25 + submission['rank3']*0.3\n",
    "submission[['id', 'failure']].to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93300918",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5204168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open('checkpoint.obj', 'wb') as fileObj :\n",
    "    pickle.dump(ensemble_models, fileObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47569c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open('checkpoint.obj', 'rb') as fileObj :\n",
    "    new_models = pickle.load(fileObj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc2dbd8",
   "metadata": {},
   "source": [
    "## Load the model back and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "583d1c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_submission = submission.copy()\n",
    "for i, model in enumerate(new_models):\n",
    "    new_submission[f\"lr{i}\"] = model.inference(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 30.268216,
   "end_time": "2022-09-01T00:06:07.473414",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-09-01T00:05:37.205198",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
