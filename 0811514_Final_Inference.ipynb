{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfdba209",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from colorama import Fore, Back, Style\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import itertools\n",
    "from tqdm.auto import tqdm\n",
    "from collections import defaultdict\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LogisticRegression, HuberRegressor\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from scipy.stats import pearsonr, spearmanr, rankdata\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaa41242",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('./input/test.csv')\n",
    "submission = pd.read_csv('./input/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4acfd68",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21f5bf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = test.copy()\n",
    "data['m3_missing'] = data['measurement_3'].isnull().astype(np.int8)\n",
    "data['m5_missing'] = data['measurement_5'].isnull().astype(np.int8)\n",
    "data['loading'] = np.log1p(data['loading'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2983abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code F has 420 samples to fill nan\n",
      "KNN imputing code F\n",
      "code G has 373 samples to fill nan\n",
      "KNN imputing code G\n",
      "code H has 361 samples to fill nan\n",
      "KNN imputing code H\n",
      "code I has 377 samples to fill nan\n",
      "KNN imputing code I\n"
     ]
    }
   ],
   "source": [
    "feature = [f for f in test.columns if f.startswith('measurement') or f=='loading']\n",
    "fill_dict = {\n",
    "    'A': ['measurement_5','measurement_6','measurement_8'],\n",
    "    'B': ['measurement_4','measurement_5','measurement_7'],\n",
    "    'C': ['measurement_5','measurement_7','measurement_8','measurement_9'],\n",
    "    'D': ['measurement_5','measurement_6','measurement_7','measurement_8'],\n",
    "    'E': ['measurement_4','measurement_5','measurement_6','measurement_8'],\n",
    "    'F': ['measurement_4','measurement_5','measurement_6','measurement_7'],\n",
    "    'G': ['measurement_4','measurement_6','measurement_8','measurement_9'],\n",
    "    'H': ['measurement_4','measurement_5','measurement_7','measurement_8','measurement_9'],\n",
    "    'I': ['measurement_3','measurement_7','measurement_8']\n",
    "}\n",
    "\n",
    "for code in data.product_code.unique():\n",
    "    tmp = data[data.product_code==code]\n",
    "    column = fill_dict[code]\n",
    "    tmp_train = tmp[column+['measurement_17']].dropna(how='any')\n",
    "    tmp_test = tmp[(tmp[column].isnull().sum(axis=1)==0)&(tmp['measurement_17'].isnull())]\n",
    "    print(f\"code {code} has {len(tmp_test)} samples to fill nan\")\n",
    "    model = HuberRegressor()\n",
    "    model.fit(tmp_train[column], tmp_train['measurement_17'])\n",
    "    data.loc[(data.product_code==code)&(data[column].isnull().sum(axis=1)==0)&(data['measurement_17'].isnull()), 'measurement_17'] = model.predict(tmp_test[column])\n",
    "\n",
    "    model2 = KNNImputer(n_neighbors=5)\n",
    "    print(f\"KNN imputing code {code}\")\n",
    "    data.loc[data.product_code==code, feature] = model2.fit_transform(data.loc[data.product_code==code, feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c012caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b53363",
   "metadata": {},
   "source": [
    "## Model and util funciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb99f66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scaler(train_data, feats):\n",
    "    scaler = StandardScaler()\n",
    "    # scaler = PowerTransformer()\n",
    "    \n",
    "    scaled_train = scaler.fit(train_data[feats])\n",
    "\n",
    "    \n",
    "    #back to dataframe\n",
    "    new_train = train_data.copy()\n",
    "\n",
    "    \n",
    "    new_train[feats] = scaled_train\n",
    "\n",
    "    \n",
    "    assert len(train_data) == len(new_train)\n",
    "\n",
    "    return scaler\n",
    "\n",
    "def apply_transform(data, scaler, feats):\n",
    "    \n",
    "    #back to dataframe\n",
    "    scaled_data = scaler.transform(data[feats])\n",
    "    new_data = data.copy()\n",
    "    \n",
    "    \n",
    "    new_data [feats] = scaled_data\n",
    "\n",
    "    \n",
    "    assert len(new_data) == len(data)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e141ffef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TPSSolver:\n",
    "    def __init__(self):\n",
    "        self.models = []\n",
    "        self.model_feature_importance_lists = []\n",
    "        self.standScalers = []\n",
    "    def train(self, X, y, k_fold_split_nums = 5, select_feature = None):\n",
    "        lr_oof_1 = np.zeros(len(train))\n",
    "        lr_oof_2 = np.zeros(len(train))\n",
    "        lr_auc = 0\n",
    "        lr_acc = 0\n",
    "        kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "        for fold_idx, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "            print(\"Fold:\", fold_idx+1)\n",
    "            x_train, x_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            #x_test = test.copy()\n",
    "\n",
    "            #x_train, x_val = _scale(x_train, x_val, select_feature)\n",
    "            scaler = get_scaler(x_train, select_feature)\n",
    "            self.standScalers.append(scaler)\n",
    "            x_train = apply_transform(x_train,scaler,  select_feature)\n",
    "            x_val =  apply_transform( x_val, scaler, select_feature)\n",
    "            model = LogisticRegression(max_iter=1000, C=0.0001, penalty='l2', solver='newton-cg') # , class_weight='balanced'\n",
    "            model.fit(x_train[select_feature], y_train)\n",
    "            self.models.append((model, select_feature))\n",
    "            self.model_feature_importance_lists.append(model.coef_.ravel())\n",
    "\n",
    "            val_preds = model.predict_proba(x_val[select_feature])[:, 1]\n",
    "            lr_auc += roc_auc_score(y_val, val_preds) / 5\n",
    "            y_preds = model.predict(x_val[select_feature])\n",
    "            lr_acc += accuracy_score(y_val, y_preds) / 5\n",
    "            lr_oof_1[val_idx] = val_preds\n",
    "            lr_oof_2[val_idx] = y_preds\n",
    "        \n",
    "        print(f\"{Fore.GREEN}{Style.BRIGHT}Average auc = {round(lr_auc, 5)}, Average acc = {round(lr_acc, 5)}{Style.RESET_ALL}\")\n",
    "        print(f\"{Fore.RED}{Style.BRIGHT}OOF auc = {round(roc_auc_score(y, lr_oof_1), 5)}, OOF acc = {round(accuracy_score(y, lr_oof_2), 5)}{Style.RESET_ALL}\")\n",
    "    \n",
    "    def visualization_importance_scores():\n",
    "        importance_list =  self.model_feature_importance_lists\n",
    "        importance_df = pd.DataFrame(np.array(importance_list).T, index=x_train[select_feature].columns)\n",
    "        importance_df['mean'] = importance_df.mean(axis=1).abs()\n",
    "        importance_df['feature'] = x_train[select_feature].columns\n",
    "        importance_df = importance_df.sort_values('mean', ascending=False).reset_index().head(20)\n",
    "        plt.barh(importance_df.index, importance_df['mean'], color='lightgreen')\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.yticks(ticks=importance_df.index, labels=importance_df['feature'])\n",
    "        plt.title('LogisticRegression feature importances')\n",
    "        plt.show()\n",
    "        \n",
    "    def inference(self, X):\n",
    "        lr_inference = np.zeros(len(X))\n",
    "        for scaler, (model, select_feature) in zip(self.standScalers,self.models):\n",
    "            x_inference = apply_transform(X, scaler, select_feature)\n",
    "            lr_inference += model.predict_proba(x_inference[select_feature])[:, 1] / len(self.models)\n",
    "        return lr_inference\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e3f7f9",
   "metadata": {},
   "source": [
    "## Load model from file and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea72b9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open('checkpoint.obj', 'rb') as fileObj :\n",
    "    new_models = pickle.load(fileObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98a1a434",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, model in enumerate(new_models):\n",
    "    submission[f\"lr{i}\"] = model.inference(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b7ee99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['rank0'] = rankdata(submission['lr0'])\n",
    "submission['rank1'] = rankdata(submission['lr1'])\n",
    "submission['rank2'] = rankdata(submission['lr2'])\n",
    "submission['rank3'] = rankdata(submission['lr3'])\n",
    "submission['failure'] = submission['rank0']*0.2 + submission['rank1']*0.25 + submission['rank2']*0.25 + submission['rank3']*0.3\n",
    "submission[['id', 'failure']].to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
